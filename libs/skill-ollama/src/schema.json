{
  "openapi": "3.0.0",
  "info": {
    "title": "@digipair/skill-ollama",
    "summary": "Communication with an Ollama server",
    "description": "Execution of LLM models via an Ollama server.",
    "version": "0.1.0",
    "x-icon": "ðŸš€"
  },
  "paths": {
    "/model": {
      "post": {
        "tags": ["service"],
        "summary": "Ollama LLM Model",
        "description": "Execution of an LLM model from an Ollama server",
        "parameters": [
          {
            "name": "model",
            "summary": "Model Name",
            "required": true,
            "description": "Name of the LLM model to load",
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "temperature",
            "summary": "Temperature",
            "required": false,
            "description": "Temperature of the LLM model",
            "schema": {
              "type": "number"
            }
          },
          {
            "name": "baseUrl",
            "summary": "Server Address",
            "required": false,
            "description": "Address of the Ollama server",
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "format",
            "summary": "Output Format",
            "required": false,
            "description": "Output format of the data generated by the model",
            "schema": {
              "type": "string"
            }
          }
        ],
        "x-events": [],
        "responses": {
          "200": {
            "description": "Ollama LLM model instance created successfully",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "description": "LangChain ChatOllama model instance ready for conversation",
                  "properties": {
                    "model": {
                      "type": "string",
                      "description": "Model name (e.g., mistral, llama2, codellama)"
                    },
                    "temperature": {
                      "type": "number",
                      "description": "Model temperature setting"
                    },
                    "baseUrl": {
                      "type": "string",
                      "description": "Ollama server URL"
                    },
                    "keepAlive": {
                      "type": "string",
                      "description": "Model keep-alive duration"
                    }
                  }
                }
              }
            }
          },
          "400": {
            "description": "Bad request - Invalid model name or parameters"
          },
          "503": {
            "description": "Service unavailable - Ollama server not reachable"
          },
          "500": {
            "description": "Server error - Model loading or initialization error"
          }
        }
      }
    },
    "/embeddings": {
      "post": {
        "tags": ["service"],
        "summary": "Ollama Embeddings Model",
        "description": "Execution of an embeddings model from an Ollama server",
        "parameters": [
          {
            "name": "model",
            "summary": "Model Name",
            "required": true,
            "description": "Name of the embeddings model to load",
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "temperature",
            "summary": "Temperature",
            "required": false,
            "description": "Temperature of the embeddings model",
            "schema": {
              "type": "number"
            }
          },
          {
            "name": "baseUrl",
            "summary": "Server Address",
            "required": false,
            "description": "Address of the Ollama server",
            "schema": {
              "type": "string"
            }
          }
        ],
        "x-events": [],
        "responses": {
          "200": {
            "description": "Ollama embeddings model instance created successfully",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "description": "LangChain OllamaEmbeddings model instance ready for text embedding",
                  "properties": {
                    "model": {
                      "type": "string",
                      "description": "Embeddings model name (e.g., nomic-embed-text, all-minilm)"
                    },
                    "baseUrl": {
                      "type": "string",
                      "description": "Ollama server URL"
                    },
                    "dimensions": {
                      "type": "number",
                      "description": "Embedding vector dimensions"
                    }
                  }
                }
              }
            }
          },
          "400": {
            "description": "Bad request - Invalid embeddings model name or parameters"
          },
          "503": {
            "description": "Service unavailable - Ollama server not reachable"
          },
          "500": {
            "description": "Server error - Embeddings model loading or initialization error"
          }
        }
      }
    }
  },
  "components": {
    "schemas": {}
  }
}
